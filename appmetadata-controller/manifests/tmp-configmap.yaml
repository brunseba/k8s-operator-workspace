apiVersion: v1
kind: ConfigMap
metadata:
  name: appmetadata-controller-code
  namespace: appmetadata-system
data:
  config.yaml: |
    logging:
      level: INFO
      format: json
      handlers:
        - console

    metrics:
      enabled: true
      port: 9090
      path: /metrics

    validation:
      strict: true
      verify_git_repos: true
      strict_dependency_checks: true
      auto_id_prefix: app-
      max_components: 20
      max_dependencies: 10
      max_maintainers: 5
      max_tags: 10
      reserved_tags:
        - system
        - legacy
        - critical
        - deprecated

    reconcile_interval: 300  # 5 minutes

    version: "1.0.0"

  __init__.py: |
    """
    Controller package for ApplicationMetadata.
    """

  __main__.py: |
    """
    Main entry point for ApplicationMetadata controller.
    """
    import asyncio
    import logging
    import os
    import signal
    import sys

    import kopf
    from prometheus_client import start_http_server

    from controller.config import load_config
    from controller import handlers  # This imports and registers all kopf handlers

    # Initialize logging
    logger = logging.getLogger(__name__)

    def main():
        """Main entry point."""
        # Load configuration
        config = load_config()
        
        # Configure logging
        log_level = getattr(logging, config.logging.level.upper())
        logging.basicConfig(
            level=log_level,
            format=config.logging.format
        )
        
        # Start metrics server if enabled
        if config.metrics.enabled:
            try:
                start_http_server(config.metrics.port)
                logger.info(f"ðŸ“Š Started metrics server on port {config.metrics.port}")
            except Exception as e:
                logger.error(f"âŒ Failed to start metrics server: {e}")
                sys.exit(1)
        
        # Log startup
        logger.info("ðŸš€ Starting ApplicationMetadata Controller")
        logger.info(f"âš™ï¸  Configuration loaded: {config.dict()}")
        
        # Register signal handlers
        def signal_handler(sig, frame):
            logger.info("ðŸ“¥ Shutting down gracefully...")
            sys.exit(0)
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # Start kopf
        kopf.run()

    if __name__ == "__main__":
        main()

  handlers.py: |
    """
    Core handlers for ApplicationMetadata controller.
    """
    import asyncio
    import logging
    from datetime import datetime, timezone
    from typing import Dict, Any, Optional, List

    import kopf
    import httpx
    from kubernetes import client

    from controller.config import ControllerConfig, load_config
    from controller.models import (
        ApplicationMetadata,
        ApplicationMetadataSpec,
        ApplicationMetadataStatus,
        Phase,
        ConditionType,
        ConditionStatus,
        Condition,
    )
    from controller.metrics import update_app_metrics

    # Initialize logging
    logger = logging.getLogger(__name__)

    # Global configuration
    config: ControllerConfig = load_config()

    def create_condition(
        condition_type: ConditionType,
        status: ConditionStatus,
        reason: str,
        message: str
    ) -> Dict[str, Any]:
        """Create a status condition."""
        return {
            "type": condition_type.value,
            "status": status.value,
            "lastTransitionTime": datetime.now(timezone.utc).isoformat(),
            "reason": reason,
            "message": message,
        }

    async def verify_git_repository(url: str) -> tuple[bool, str]:
        """Verify that a Git repository exists and is accessible."""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.head(url, follow_redirects=True)
                return response.status_code == 200, "Repository verified"
        except Exception as e:
            return False, f"Failed to verify repository: {str(e)}"

    async def verify_dependencies(
        components: List[Dict[str, Any]]
    ) -> tuple[bool, List[str]]:
        """Verify that all component dependencies exist."""
        component_names = {comp["name"] for comp in components}
        errors = []
        
        for component in components:
            if "dependencies" in component:
                for dep in component["dependencies"]:
                    if dep not in component_names:
                        errors.append(
                            f"Component '{component['name']}' depends on '{dep}' which does not exist"
                        )
        
        return len(errors) == 0, errors

    async def check_component_health(
        component: Dict[str, Any]
    ) -> tuple[bool, str]:
        """Check health of a component."""
        # This is a simplified health check
        # In production, you would:
        # 1. Check actual component health (e.g., database connectivity)
        # 2. Check associated resources (pods, services, etc.)
        # 3. Run component-specific health checks
        return True, f"Component '{component['name']}' is healthy"

    @kopf.on.startup()
    def configure(settings: kopf.OperatorSettings, **_):
        """Configure the operator."""
        settings.posting.level = logging.INFO
        settings.watching.connect_timeout = 60
        settings.watching.server_timeout = 600
        
        # Set up logging
        log_level = getattr(logging, config.logging.level.upper())
        logging.basicConfig(
            level=log_level,
            format=config.logging.format
        )
        
        logger.info(f"ðŸš€ Starting ApplicationMetadata controller v{config.version}")
        logger.info(f"âš™ï¸ Configuration loaded: {config.dict()}")

    @kopf.on.create("apps.company.io", "v1", "applicationmetadata")
    async def create_fn(spec: Dict[str, Any], meta: Dict[str, Any], logger: logging.Logger, **kwargs):
        """Handle creation of ApplicationMetadata resources."""
        name = meta["name"]
        namespace = meta["namespace"]
        logger.info(f"ðŸ“¦ Creating ApplicationMetadata: {namespace}/{name}")
        
        try:
            # Validate using Pydantic model
            app_spec = ApplicationMetadataSpec(**spec)
            
            # Verify Git repositories if enabled
            if config.validation.verify_git_repos:
                if app_spec.tracking.repository:
                    repo_ok, repo_msg = await verify_git_repository(str(app_spec.tracking.repository))
                    if not repo_ok:
                        return {
                            "status": "error",
                            "message": repo_msg
                        }
            
            # Verify dependencies if enabled
            if config.validation.strict_dependency_checks:
                deps_ok, errors = await verify_dependencies(spec.get("composition", []))
                if not deps_ok:
                    return {
                        "status": "error",
                        "message": "; ".join(errors)
                    }
            
            # Set initial status
            status = ApplicationMetadataStatus(
                phase=Phase.PENDING,
                conditions=[
                    Condition(
                        type=ConditionType.READY,
                        status=ConditionStatus.UNKNOWN,
                        lastTransitionTime=datetime.now(timezone.utc),
                        reason="Initializing",
                        message=f"Initializing application {name}"
                    )
                ],
                lastUpdated=datetime.now(timezone.utc),
                observedVersion=spec["version"],
                observedGeneration=meta.get("generation", 1)
            )
            
            # Update metrics
            update_app_metrics(name, namespace, status)
            
            return {"status": status.dict()}
            
        except Exception as e:
            logger.error(f"âŒ Failed to create ApplicationMetadata {namespace}/{name}: {e}")
            raise kopf.PermanentError(f"Failed to create resource: {e}")

    @kopf.on.update("apps.company.io", "v1", "applicationmetadata")
    async def update_fn(spec: Dict[str, Any], meta: Dict[str, Any], status: Dict[str, Any], logger: logging.Logger, **kwargs):
        """Handle updates to ApplicationMetadata resources."""
        name = meta["name"]
        namespace = meta["namespace"]
        logger.info(f"ðŸ“ Updating ApplicationMetadata: {namespace}/{name}")
        
        try:
            # Re-validate using Pydantic model
            app_spec = ApplicationMetadataSpec(**spec)
            
            # Check health of components
            healthy_components = []
            unhealthy_components = []
            
            for component in app_spec.composition:
                is_healthy, message = await check_component_health(component.dict())
                if is_healthy:
                    healthy_components.append(component.name)
                else:
                    unhealthy_components.append((component.name, message))
            
            # Determine overall health
            all_healthy = len(unhealthy_components) == 0
            health_status = ConditionStatus.TRUE if all_healthy else ConditionStatus.FALSE
            health_reason = "AllComponentsHealthy" if all_healthy else "UnhealthyComponents"
            health_message = (
                "All components are healthy"
                if all_healthy
                else f"Unhealthy components: {', '.join(c[0] for c in unhealthy_components)}"
            )
            
            # Update status
            new_status = ApplicationMetadataStatus(
                phase=Phase.ACTIVE if all_healthy else Phase.PENDING,
                conditions=[
                    Condition(
                        type=ConditionType.HEALTHY,
                        status=health_status,
                        lastTransitionTime=datetime.now(timezone.utc),
                        reason=health_reason,
                        message=health_message
                    ),
                    Condition(
                        type=ConditionType.READY,
                        status=ConditionStatus.TRUE,
                        lastTransitionTime=datetime.now(timezone.utc),
                        reason="ValidationPassed",
                        message="Application validated successfully"
                    )
                ],
                lastUpdated=datetime.now(timezone.utc),
                observedVersion=spec["version"],
                observedGeneration=meta.get("generation", 1)
            )
            
            # Update metrics
            update_app_metrics(name, namespace, new_status)
            
            return {"status": new_status.dict()}
            
        except Exception as e:
            logger.error(f"âŒ Failed to update ApplicationMetadata {namespace}/{name}: {e}")
            raise kopf.PermanentError(f"Failed to update resource: {e}")

    @kopf.on.delete("apps.company.io", "v1", "applicationmetadata")
    async def delete_fn(meta: Dict[str, Any], logger: logging.Logger, **kwargs):
        """Handle deletion of ApplicationMetadata resources."""
        name = meta["name"]
        namespace = meta["namespace"]
        logger.info(f"ðŸ—‘ï¸ Deleting ApplicationMetadata: {namespace}/{name}")
        
        try:
            # Update metrics (remove)
            update_app_metrics(name, namespace, None, deleted=True)
            
            logger.info(f"âœ… Successfully deleted ApplicationMetadata {namespace}/{name}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to delete ApplicationMetadata {namespace}/{name}: {e}")
            raise kopf.PermanentError(f"Failed to delete resource: {e}")

    @kopf.timer("apps.company.io", "v1", "applicationmetadata",
                interval=config.reconcile_interval)
    async def reconcile_fn(spec: Dict[str, Any], meta: Dict[str, Any], status: Dict[str, Any], logger: logging.Logger, **kwargs):
        """Periodically reconcile ApplicationMetadata resources."""
        name = meta["name"]
        namespace = meta["namespace"]
        logger.debug(f"ðŸ”„ Reconciling ApplicationMetadata: {namespace}/{name}")
        
        try:
            # Re-validate and check health
            app_spec = ApplicationMetadataSpec(**spec)
            current_status = ApplicationMetadataStatus(**status)
            
            # Check Git repositories
            if config.validation.verify_git_repos:
                if app_spec.tracking.repository:
                    repo_ok, _ = await verify_git_repository(str(app_spec.tracking.repository))
                    if not repo_ok:
                        current_status.phase = Phase.ERROR
                        current_status.conditions.append(
                            Condition(
                                type=ConditionType.READY,
                                status=ConditionStatus.FALSE,
                                lastTransitionTime=datetime.now(timezone.utc),
                                reason="RepositoryNotAccessible",
                                message=f"Repository {app_spec.tracking.repository} is not accessible"
                            )
                        )
                        return {"status": current_status.dict()}
            
            # Check component health
            healthy_components = []
            unhealthy_components = []
            
            for component in app_spec.composition:
                is_healthy, message = await check_component_health(component.dict())
                if is_healthy:
                    healthy_components.append(component.name)
                else:
                    unhealthy_components.append((component.name, message))
            
            # Update status based on health
            all_healthy = len(unhealthy_components) == 0
            if all_healthy and current_status.phase != Phase.ACTIVE:
                current_status.phase = Phase.ACTIVE
                current_status.conditions.append(
                    Condition(
                        type=ConditionType.HEALTHY,
                        status=ConditionStatus.TRUE,
                        lastTransitionTime=datetime.now(timezone.utc),
                        reason="AllComponentsHealthy",
                        message="All components are healthy"
                    )
                )
            elif not all_healthy and current_status.phase == Phase.ACTIVE:
                current_status.phase = Phase.PENDING
                current_status.conditions.append(
                    Condition(
                        type=ConditionType.HEALTHY,
                        status=ConditionStatus.FALSE,
                        lastTransitionTime=datetime.now(timezone.utc),
                        reason="UnhealthyComponents",
                        message=f"Unhealthy components: {', '.join(c[0] for c in unhealthy_components)}"
                    )
                )
            
            # Update metrics
            update_app_metrics(name, namespace, current_status)
            
            return {"status": current_status.dict()}
            
        except Exception as e:
            logger.error(f"âŒ Failed to reconcile ApplicationMetadata {namespace}/{name}: {e}")
            # Don't raise error - let it retry next reconciliation

  metrics.py: |
    """
    Prometheus metrics for ApplicationMetadata controller.
    """
    import logging
    from typing import Dict, Optional

    from prometheus_client import Counter, Gauge, Histogram
    from controller.models import ApplicationMetadataStatus, Phase

    # Initialize logger
    logger = logging.getLogger(__name__)

    # Metrics definitions
    APPS_TOTAL = Gauge(
        "appmetadata_applications_total",
        "Total number of applications by phase",
        ["phase"]
    )

    APPS_BY_ENVIRONMENT = Gauge(
        "appmetadata_applications_by_environment",
        "Number of applications by environment",
        ["environment"]
    )

    APPS_BY_BUSINESS_UNIT = Gauge(
        "appmetadata_applications_by_business_unit",
        "Number of applications by business unit",
        ["business_unit"]
    )

    COMPONENT_COUNT = Gauge(
        "appmetadata_components_total",
        "Total number of components by type",
        ["type"]
    )

    STATUS_CHANGES = Counter(
        "appmetadata_status_changes_total",
        "Number of application status changes",
        ["from_phase", "to_phase"]
    )

    RECONCILIATION_DURATION = Histogram(
        "appmetadata_reconciliation_duration_seconds",
        "Time spent reconciling applications",
        buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
    )

    VALIDATION_ERRORS = Counter(
        "appmetadata_validation_errors_total",
        "Number of validation errors by type",
        ["error_type"]
    )

    # Cache for tracking application phases
    _app_phases: Dict[str, str] = {}

    def _get_app_key(name: str, namespace: str) -> str:
        """Generate a unique key for an application."""
        return f"{namespace}/{name}"

    def update_app_metrics(
        name: str,
        namespace: str,
        status: Optional[ApplicationMetadataStatus],
        deleted: bool = False
    ) -> None:
        """Update metrics for an application."""
        try:
            app_key = _get_app_key(name, namespace)
            
            if deleted:
                # Decrease counters if app is deleted
                if app_key in _app_phases:
                    old_phase = _app_phases[app_key]
                    APPS_TOTAL.labels(phase=old_phase).dec()
                    del _app_phases[app_key]
                return
            
            if not status:
                return
                
            # Update phase metrics
            new_phase = status.phase
            if app_key in _app_phases:
                old_phase = _app_phases[app_key]
                if old_phase != new_phase:
                    # Phase changed
                    APPS_TOTAL.labels(phase=old_phase).dec()
                    APPS_TOTAL.labels(phase=new_phase).inc()
                    STATUS_CHANGES.labels(
                        from_phase=old_phase,
                        to_phase=new_phase
                    ).inc()
            else:
                # New application
                APPS_TOTAL.labels(phase=new_phase).inc()
            
            _app_phases[app_key] = new_phase
            
        except Exception as e:
            logger.error(f"Failed to update metrics for {namespace}/{name}: {e}")

    def record_validation_error(error_type: str) -> None:
        """Record a validation error."""
        try:
            VALIDATION_ERRORS.labels(error_type=error_type).inc()
        except Exception as e:
            logger.error(f"Failed to record validation error: {e}")

    def start_reconciliation() -> None:
        """Start timing a reconciliation operation."""
        return RECONCILIATION_DURATION.time()